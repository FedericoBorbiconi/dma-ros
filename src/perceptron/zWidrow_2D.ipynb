{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron no  lineal, de Widrow\n",
        "\n"
      ],
      "metadata": {
        "id": "wpZAAQH_AnX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Big Picture"
      ],
      "metadata": {
        "id": "ldkzf-kNOooG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src= 'https://storage.googleapis.com/open-courses/imagenes-5c33/DeepLearningTimeline.jpg' />"
      ],
      "metadata": {
        "id": "66I37uRFOu2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camino a Seguir\n",
        "\n",
        "\n",
        "*   Perceptron de Rosenblatt\n",
        "*   Perceptron de Widrow\n",
        "*   Multiperceptron, backpropagation\n"
      ],
      "metadata": {
        "id": "BGehd_mo6kjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo desde el punto de vista Matemático"
      ],
      "metadata": {
        "id": "5WLeolPFG6MX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Objetivo Primario"
      ],
      "metadata": {
        "id": "EjFvKhkJ83Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src= 'https://storage.googleapis.com/open-courses/imagenes-5c33/fuzzy.png' />\n",
        "\n",
        "<p> El primitivo perceptron de Rosenblatt del año 1958 solo funcionaba cuando los positivos y negativos eran lineamente separables. Esta limitacion provenia de que el error era o el valor 0 o el valor 1 </p>\n",
        "\n",
        "<p> El evolucionado perceptron de Widrow,  año 1960, acepta conjuntos de p8untos que no son perfectamente separables </p>\n",
        "\n",
        "<p> ära la clasificacion binaria Widrow lo logra  permitiendo funciones de error que estén en el intervalo [0,1] </p>"
      ],
      "metadata": {
        "id": "YczJGmypG9sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Objetivo Secundario"
      ],
      "metadata": {
        "id": "4FoAcJe-88SD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El sequndo objetivo en el caso que sean linealmente separables, **evitar** que  sucedan este tipo de soluciones donde la recta se \"pega\" a uno de los puntos ya que esa condición alcanzaba para que Rosenblatt se detuviera\n",
        "\n",
        "%%html\n",
        "<img src= 'https://storage.googleapis.com/open-courses/imagenes-5c33/recta_overfitera.jpg' />\n"
      ],
      "metadata": {
        "id": "ZcPlZGq26-HJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajo de Bernard Widrow"
      ],
      "metadata": {
        "id": "uDSWsj2KDpkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernard Widrow (posee 95 años a marzo-2025), en video de 2015, explicando su algoritmo"
      ],
      "metadata": {
        "id": "9XKXnyORKpxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[The LMS algorithm and ADALINE. Part I - The LMS algorithm](https://youtu.be/hc2Zj55j1zU)\n"
      ],
      "metadata": {
        "id": "qLaHQ6PwA-sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "parte II, haciendo una demo"
      ],
      "metadata": {
        "id": "EZqfXGDUKGwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[The LMS algorithm and ADALINE. Part II - ADALINE and memistor ADALINE](https://youtu.be/skfNlwEbqck)\n"
      ],
      "metadata": {
        "id": "48b7mvP0JJKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concepto matemático de Perceptron"
      ],
      "metadata": {
        "id": "3VkoYsz0DtkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/perceptron_elemental.jpg' />\n"
      ],
      "metadata": {
        "id": "Z_QPjmzJDz1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/activation_function.png' />\n",
        "\n",
        "Funcion de activacion escalón  {0,1}\n"
      ],
      "metadata": {
        "id": "j6ssdibgLZSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones de activacion"
      ],
      "metadata": {
        "id": "_00qTXojaykH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primitivo perceptrón de Ronsenblatt solo permitía la función de activacion de escalon\n",
        "\n",
        "El perceptron de Windrow permite funciones de activacion arbitrarias, en la media que sean derivables\n",
        "\n",
        "Utilizaremos para clasificacion alguna de estas dos funciones de activacion\n",
        "\n",
        "\n",
        "*  **logsig**   función logistica    R -> (0, 1 )\n",
        "*  **tansig**  funcion logistica   R -> ( -1, 1 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Utilizaremos para \"Adaline\"  esta funcion de activacion\n",
        "\n",
        "*   **purelin**   recta identidad  R -> R\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YabKTbqX9Nta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **purelin** funcion Lineal Adaline"
      ],
      "metadata": {
        "id": "lREWQJwvWwoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/purelin.jpg' />"
      ],
      "metadata": {
        "id": "Vvar-hHBW1hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **logsig** funcion Logistica  R -> (0, 1 )"
      ],
      "metadata": {
        "id": "bgRzXQc9a2dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/LogisticFunction.png' />"
      ],
      "metadata": {
        "id": "84BSHDtsbBv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derivación de la derivada de la función logistica"
      ],
      "metadata": {
        "id": "zNPrmA9b-uFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/LogisticDerivative.jpg' />\n",
        "<p>Derivada de la funcion logística, expresada en funcion de si misma</p>"
      ],
      "metadata": {
        "id": "J1EBO5eecMoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/logsig.jpg' />"
      ],
      "metadata": {
        "id": "rXc4gsc5iPM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **tansig** tangente Hiperbolica   R -> (-1, 1 )"
      ],
      "metadata": {
        "id": "ty78q4Zggqmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/tanh-sigmoid.png' />'"
      ],
      "metadata": {
        "id": "20-_ECgRgwdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/tansig.jpg' />'"
      ],
      "metadata": {
        "id": "kEq_xwqwhvKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización  del Mean Squared Error"
      ],
      "metadata": {
        "id": "7LiiTEo6_DsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descenso del Gradiente"
      ],
      "metadata": {
        "id": "BtfeV0P6VyHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/grad_descent_01.jpg' />"
      ],
      "metadata": {
        "id": "mvJk8dzJXI5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se quiere optimizar"
      ],
      "metadata": {
        "id": "PzCPtljebwBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/grad_descent_02.jpg' />"
      ],
      "metadata": {
        "id": "gPsFdN4kXPmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/grad_descent_03.jpg' />"
      ],
      "metadata": {
        "id": "xl_s8pDJXRxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/grad_descent_04.jpg' />"
      ],
      "metadata": {
        "id": "X8KfnADyXUI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pseudocódigo del Algoritmo de Widrow"
      ],
      "metadata": {
        "id": "tPXCnr1FVsme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src='https://storage.googleapis.com/open-courses/imagenes-5c33/WidrowAlgoritmo.jpg' />"
      ],
      "metadata": {
        "id": "xcCGzEJ0XHSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código en Python del Algoritmo de Widrow"
      ],
      "metadata": {
        "id": "f3MCES9WMJEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código en Python que grafica como va evolucionando la recta que separa a los positivos de los negativos"
      ],
      "metadata": {
        "id": "GsDfkqXaZR5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')\n",
        "!mkdir -p \"/content/.drive/My Drive/DMA\"\n",
        "!mkdir -p \"/content/buckets\"\n",
        "!ln -s \"/content/.drive/My Drive/DMA\" /content/buckets/b1"
      ],
      "metadata": {
        "id": "_0XkHjieK2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ejqYzmGGLADY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo, usted deberá generar sus propios puntos en el plano\n",
        "#  los que mandatoriamente deben ser separables por una recta\n",
        "#  los puntos traen incorporada la dimension artificial x0\n",
        "#  <x0, x1, x2>    donde    x0 = 1\n",
        "\n",
        "registros = [ [1, 0.7, 1.3], [1, 2.0, 1.1], [1, 1.0, 1.9],\n",
        "            [1, 3.0, 1.0], [1, 1.5, 2.1] ]\n",
        "clases = [0,0,0,1,1]\n"
      ],
      "metadata": {
        "id": "SpZ4JF8pLD11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso las listas a numpy\n",
        "X = np.array(registros)\n",
        "Y = np.array(clases)"
      ],
      "metadata": {
        "id": "g8vhhU-qLNz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estandarizo X\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# vuelvo a 1.0  x0\n",
        "X[:,0] = 1.0"
      ],
      "metadata": {
        "id": "yuuuDs1d1xI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamano datos\n",
        "X_row = X.shape[0]\n",
        "X_col = X.shape[1]"
      ],
      "metadata": {
        "id": "lvJ_Peb2bLWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definicion de las funciones de activacion\n",
        "#  y sus derivadas\n",
        "\n",
        "def func_eval(fname, x):\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            y = x\n",
        "        case \"logsig\":\n",
        "            y = 1.0 / ( 1.0 + math.exp(-x) )\n",
        "        case \"tansig\":\n",
        "            y = 2.0 / ( 1.0 + math.exp(-2.0*x) ) - 1.0\n",
        "    return y\n",
        "\n",
        "def deriv_eval(fname, y):  #atencion que y es la entrada y=f( x )\n",
        "    match fname:\n",
        "        case \"purelin\":\n",
        "            d = 1.0\n",
        "        case \"logsig\":\n",
        "            d = y*(1.0-y)\n",
        "        case \"tansig\":\n",
        "            d = 1.0 - y*y\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "3lzEFCiIaexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definicion de la clase de graficos\n",
        "\n",
        "class perceptron_plot:\n",
        "    def __init__(self, X, Y, delay) -> None:\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.delay = delay\n",
        "        x1_min = np.min(X[:,1])\n",
        "        x2_min = np.min(X[:,2])\n",
        "        x1_max = np.max(X[:,1])\n",
        "        x2_max = np.max(X[:,2])\n",
        "        self.x1_min = x1_min - 0.75*(x1_max - x1_min)\n",
        "        self.x1_max = x1_max + 0.75*(x1_max - x1_min)\n",
        "        self.x2_min = x2_min - 0.75*(x2_max - x2_min)\n",
        "        self.x2_max = x2_max + 0.75*(x2_max - x2_min)\n",
        "        self.fig = plt.figure(figsize = (10,8))\n",
        "        self.ax = self.fig.subplots()\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max, auto=False)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max, auto=False)\n",
        "\n",
        "    def graficar(self, W, epoch, fila, error) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + str(fila)  + ' error ' + str(error))\n",
        "        # ploteo puntos positivos\n",
        "        self.ax.plot(self.X[self.Y==1,1], self.X[self.Y==1,2], 'o', color=\"green\", markersize=10)\n",
        "        # ploteo puntos negativos\n",
        "        self.ax.plot(self.X[self.Y==0,1], self.X[self.Y==0,2], 'o', color=\"blue\", markersize=10)\n",
        "\n",
        "        # Sobreploteo el punto que no coincidio\n",
        "        if(fila>=0):\n",
        "            self.ax.plot(self.X[fila,1], self.X[fila,2], 'o',\n",
        "                         color= ('green' if self.Y[fila]==1 else 'blue'),\n",
        "                         markersize= 12, markeredgecolor= 'red')\n",
        "\n",
        "        #dibujo le recta\n",
        "        vx2_min = -(W[1]*self.x1_min + W[0])/W[2]\n",
        "        vx2_max = -(W[1]*self.x1_max + W[0])/W[2]\n",
        "\n",
        "        self.ax.plot([self.x1_min, self.x1_max],\n",
        "                     [vx2_min, vx2_max],\n",
        "                     linewidth = 2,\n",
        "                     color = 'red',\n",
        "                     alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n",
        "\n",
        "\n",
        "    def graficarVarias(self, W, epoch, fila, error) -> None:\n",
        "        display.clear_output(wait =True)\n",
        "        plt.cla()\n",
        "        #self.ax = self.fig.subplots()\n",
        "\n",
        "        self.ax.set_xlim(self.x1_min, self.x1_max)\n",
        "        self.ax.set_ylim(self.x2_min, self.x2_max)\n",
        "        plt.title( 'epoch ' + str(epoch) + '  reg ' + str(fila) + ' error ' + str(error))\n",
        "        # ploteo puntos positivos\n",
        "        self.ax.plot(self.X[self.Y==1,1], self.X[self.Y==1,2], 'o', color=\"green\", markersize=10)\n",
        "        # ploteo puntos negativos\n",
        "        self.ax.plot(self.X[self.Y==-1,1], self.X[self.Y==-1,2], 'o', color=\"blue\", markersize=10)\n",
        "        self.ax.plot(self.X[self.Y==0,1], self.X[self.Y==0,2], 'o', color=\"blue\", markersize=10)\n",
        "\n",
        "        # Sobreploteo el punto que no coincidio\n",
        "        if(fila>=0):\n",
        "            self.ax.plot(self.X[fila,1], self.X[fila,2], 'o',\n",
        "                         color= ('green' if self.Y[fila]==1 else 'blue'),\n",
        "                         markersize= 12, markeredgecolor= 'red')\n",
        "\n",
        "        # dibujo las rectas\n",
        "        for i in range(len(x0)):\n",
        "            #vx2_min = -(W[0,i]*self.x1_min + x0[i])/W[1,i]\n",
        "            #vx2_max = -(W[0,i]*self.x1_max + x0[i])/W[1,i]\n",
        "            vx2_min = -(W[i,1]*self.x1_min + W[i,0])/W[i,2]\n",
        "            vx2_max = -(W[i,1]*self.x1_max + W[i,0])/W[i,2]\n",
        "\n",
        "            self.ax.plot([self.x1_min, self.x1_max],\n",
        "                         [vx2_min, vx2_max],\n",
        "                         linewidth = 2,\n",
        "                         color = 'red',\n",
        "                         alpha = 0.5)\n",
        "\n",
        "        display.display(plt.gcf())\n",
        "        #plt.cla()\n",
        "        time.sleep(self.delay)\n"
      ],
      "metadata": {
        "id": "3bYjXyHqLQFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incializo la recta azarosamente\n",
        "\n",
        "# seteo de la semilla aleatoria\n",
        "np.random.seed(102191) # mi querida random seed para que las corridas sean reproducibles"
      ],
      "metadata": {
        "id": "Sr3jG9g7fPeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializo < x0, W >\n",
        "W = np.array( np.random.uniform(-0.5, 0.5, size=X_col))"
      ],
      "metadata": {
        "id": "pWseyXcQLklN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limite de lo que estoy dispuesto a trabajar\n",
        "epoch_limit = 500    # para terminar si no converge"
      ],
      "metadata": {
        "id": "2CvW7ZS8LoUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cuando la mejora del error sea inferior a este valor, me detendré\n",
        "error_delta_umbral = 0.0002"
      ],
      "metadata": {
        "id": "cKITdTEUj8m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funcion activacion\n",
        "funcion_activacion = 'logsig'  # uso la logistica"
      ],
      "metadata": {
        "id": "npfvHg7ywGj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# controla la velocidad de convergencia\n",
        "learning_rate = 0.2"
      ],
      "metadata": {
        "id": "5iVeHxOJjFIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# controla cada cuanto se grafica un epoch\n",
        "demora_impresion = 0.5  # segundos"
      ],
      "metadata": {
        "id": "0M0JUxEgY2vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializaciones del bucle\n",
        "epoch = 0"
      ],
      "metadata": {
        "id": "s8oBAECNjKmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicilizo el error\n",
        "error_epoch = float('inf')\n",
        "error_ant =  0.0"
      ],
      "metadata": {
        "id": "nIOgkeEiyGnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el bucle principal del algoritmo de Widrow\n",
        "\n",
        "grafico = perceptron_plot(X=X, Y=Y, delay=demora_impresion)\n",
        "\n",
        "# bucle principal del algoritmo de Widrow\n",
        "# continuo mientras en la iteración anterior modifique algo  y NO llegué al límite de epochs\n",
        "while ((math.fabs(error_epoch - error_ant) > error_delta_umbral) and (epoch < epoch_limit)):\n",
        "    epoch += 1\n",
        "    error_suma = 0.0\n",
        "    error_ant = error_epoch\n",
        "\n",
        "    # recorro siempre TODOS los registros de entrada\n",
        "    for fila in range(X_row):\n",
        "        # fila es el registro actual\n",
        "        x = X[fila,]\n",
        "        clase = Y[fila]\n",
        "        # calculo el estimulo suma, producto interno\n",
        "        estimulo = W @ x\n",
        "\n",
        "        # funcion de activacion\n",
        "        y = func_eval( funcion_activacion, estimulo)\n",
        "\n",
        "        error = clase - y\n",
        "\n",
        "        error_suma += error*error # acumulo el cuadrado de los errores\n",
        "\n",
        "        gradiente = - 2.0 * error * deriv_eval(funcion_activacion,y)\n",
        "        W = W -  ( learning_rate * gradiente * x )\n",
        "\n",
        "        grafico.graficar(W, epoch, fila, error_epoch) # actualizo grafico\n",
        "\n",
        "\n",
        "    error_epoch = error_suma / X_row # calculo el error promedio"
      ],
      "metadata": {
        "id": "G7Hd3D_FLs0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico = perceptron_plot(X, Y, 0)\n",
        "grafico.graficar(W, epoch, -1, error_epoch)"
      ],
      "metadata": {
        "id": "4Zq2YUgNLwfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el error\n",
        "print(\"error_epoch= \", error_epoch)\n",
        "print(\"error_ant = \", error_ant)\n",
        "print(\"delta = \", math.fabs(error_epoch - error_ant))"
      ],
      "metadata": {
        "id": "f1eC6hRGyBxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la cantidad de epochs necesarias hasta encontrar una solucion\n",
        "print(\"Para converger hicieron falta epochs=\",epoch)"
      ],
      "metadata": {
        "id": "JB4k9EeALy-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el vector solución W, que incluye a  X0\n",
        "print( \"La solucion es W = \", W)"
      ],
      "metadata": {
        "id": "6iqEFzBOexHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la norma (longitud) del vector W\n",
        "print( ' ║W║  = ' , np.linalg.norm(W) )"
      ],
      "metadata": {
        "id": "VQli47hlszUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculo la salida de la red\n",
        "#  comprouebo que NO son valores 0 o 1\n",
        "#  lo que implica que deberé decidir mediante un umbral\n",
        "\n",
        "print( \"fila\\tclase\\testimulo\\ty\")\n",
        "for fila in range(X_row):\n",
        "    # fila es el registro actual\n",
        "    x = X[fila,]\n",
        "    clase = Y[fila]\n",
        "    # calculo el estimulo suma, producto interno\n",
        "    estimulo = W @ x\n",
        "\n",
        "    # funcion de activacion\n",
        "    y = func_eval( funcion_activacion, estimulo)\n",
        "    print( fila, \"\\t\", clase, \"\\t\", estimulo, \"\\t\", y)"
      ],
      "metadata": {
        "id": "ZSbZgl_ZoxPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ECAt2tDwKzPb"
      }
    }
  ]
}